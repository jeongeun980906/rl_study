{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from environment import Env\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSARSAgent:\n",
    "    def __init__(self):\n",
    "        self.action_space=[0,1,2,3,4]\n",
    "        self.action_size=len(self.action_space)\n",
    "        self.state_size=15\n",
    "        self.discount_factor=0.99\n",
    "        self.learning_rate=0.001\n",
    "        self.epsilon=1.\n",
    "        self.epsilon_decay=0.999\n",
    "        self.epsion_min=0.01\n",
    "        self.model=self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        model=Sequential()\n",
    "        model.add(Dense(30,input_dim=self.state_size,activation='relu'))\n",
    "        model.add(Dense(30,activation='relu'))\n",
    "        model.add(Dense(self.action_size,activation='linear'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def get_action(self,state):\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            state=np.float32(state)\n",
    "            q_values=self.model.predict(state)\n",
    "            return np.argmax(q_values[0])\n",
    "    def train_model(self,state,action,reward,next_state,next_action,done):\n",
    "        if self.epsilon>self.epsion_min:\n",
    "            self.epsilon*=self.epsilon_decay\n",
    "        state=np.float32(state)\n",
    "        next_state=np.float32(next_state)\n",
    "        target=self.model.predict(state)[0]\n",
    "        if done:\n",
    "            target[action]=reward\n",
    "        else:\n",
    "            target[action]=(reward+self.discount_factor*\n",
    "                           self.model.predict(next_state)[0][next_action])\n",
    "        target=np.reshape(target,[1,5])\n",
    "        \n",
    "        self.model.fit(state,target,epochs=1,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 1,565\n",
      "Trainable params: 1,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: -25 global_step 197   epsilon: 0.8211096960588341\n",
      "episode: 1   score: -5 global_step 280   epsilon: 0.7556778685553796\n",
      "episode: 2   score: -13 global_step 348   epsilon: 0.7059759437435444\n",
      "episode: 3   score: 0 global_step 366   epsilon: 0.6933758171534341\n",
      "episode: 4   score: 0 global_step 385   epsilon: 0.680319574690566\n",
      "episode: 5   score: -2 global_step 397   epsilon: 0.6722004915521225\n",
      "episode: 6   score: -1 global_step 417   epsilon: 0.6588834367523301\n",
      "episode: 7   score: 0 global_step 440   epsilon: 0.6438946541462667\n",
      "episode: 8   score: -4 global_step 458   epsilon: 0.632402542800493\n",
      "episode: 9   score: -3 global_step 478   epsilon: 0.6198739305429264\n",
      "episode: 10   score: -12 global_step 546   epsilon: 0.5791040088995179\n",
      "episode: 11   score: -11 global_step 599   epsilon: 0.5491961035890855\n",
      "episode: 12   score: -3 global_step 608   epsilon: 0.54427306365317\n",
      "episode: 13   score: 0 global_step 627   epsilon: 0.534024420840334\n",
      "episode: 14   score: -3 global_step 672   epsilon: 0.5105145071914643\n",
      "episode: 15   score: 0 global_step 684   epsilon: 0.5044219150017507\n",
      "episode: 16   score: 1 global_step 703   epsilon: 0.49492366792863446\n",
      "episode: 17   score: 0 global_step 716   epsilon: 0.4885281230967259\n",
      "episode: 18   score: 1 global_step 731   epsilon: 0.48125127508828036\n",
      "episode: 19   score: -1 global_step 749   epsilon: 0.4726619923492537\n",
      "episode: 20   score: 1 global_step 760   epsilon: 0.46748862900952265\n",
      "episode: 21   score: 1 global_step 772   epsilon: 0.4619095170944617\n",
      "episode: 22   score: 1 global_step 788   epsilon: 0.45457413613233344\n",
      "episode: 23   score: 1 global_step 796   epsilon: 0.45095024569472963\n",
      "episode: 24   score: 1 global_step 816   epsilon: 0.44201640942211684\n",
      "episode: 25   score: -1 global_step 827   epsilon: 0.43717846703394564\n",
      "episode: 26   score: 0 global_step 844   epsilon: 0.4298055931223125\n",
      "episode: 27   score: 1 global_step 853   epsilon: 0.42595277973599555\n",
      "episode: 28   score: 0 global_step 861   epsilon: 0.42255706035237733\n",
      "episode: 29   score: 0 global_step 876   epsilon: 0.41626288125048977\n",
      "episode: 30   score: 1 global_step 888   epsilon: 0.41129510865353336\n",
      "episode: 31   score: 1 global_step 901   epsilon: 0.4059802359226587\n",
      "episode: 32   score: 0 global_step 913   epsilon: 0.4011351786721449\n",
      "episode: 33   score: -1 global_step 921   epsilon: 0.3979373065922575\n",
      "episode: 34   score: -3 global_step 941   epsilon: 0.3900537168219873\n",
      "episode: 35   score: 0 global_step 953   epsilon: 0.3853987301463841\n",
      "episode: 36   score: 0 global_step 966   epsilon: 0.3804184978064605\n",
      "episode: 37   score: -1 global_step 980   epsilon: 0.3751271188281757\n",
      "episode: 38   score: 1 global_step 991   epsilon: 0.37102129074024554\n",
      "episode: 39   score: 0 global_step 1005   epsilon: 0.36586062092624033\n",
      "episode: 40   score: 0 global_step 1019   epsilon: 0.36077173274200636\n",
      "episode: 41   score: 0 global_step 1027   epsilon: 0.35789564031060395\n",
      "episode: 42   score: 0 global_step 1036   epsilon: 0.3546874337726758\n",
      "episode: 43   score: 1 global_step 1047   epsilon: 0.3508053214034905\n",
      "episode: 44   score: 0 global_step 1060   epsilon: 0.34627211496036764\n",
      "episode: 45   score: 1 global_step 1070   epsilon: 0.34282493457591334\n",
      "episode: 46   score: 1 global_step 1081   epsilon: 0.3390726592138397\n",
      "episode: 47   score: 0 global_step 1094   epsilon: 0.33469106557869915\n",
      "episode: 48   score: 1 global_step 1108   epsilon: 0.3300357260543739\n",
      "episode: 49   score: 1 global_step 1124   epsilon: 0.32479457450384985\n",
      "episode: 50   score: 1 global_step 1136   epsilon: 0.32091840475743094\n",
      "episode: 51   score: 0 global_step 1150   epsilon: 0.31645463417195824\n",
      "episode: 52   score: 1 global_step 1159   epsilon: 0.31361790828888503\n",
      "episode: 53   score: 0 global_step 1168   epsilon: 0.3108066110545554\n",
      "episode: 54   score: -1 global_step 1182   epsilon: 0.3064834890782873\n",
      "episode: 55   score: 1 global_step 1196   epsilon: 0.3022204989748846\n",
      "episode: 56   score: 1 global_step 1208   epsilon: 0.2986137332009687\n",
      "episode: 57   score: 1 global_step 1219   epsilon: 0.2953453567182228\n",
      "episode: 58   score: 1 global_step 1236   epsilon: 0.2903644524887822\n",
      "episode: 59   score: 1 global_step 1247   epsilon: 0.2871863657418441\n",
      "episode: 60   score: 0 global_step 1259   epsilon: 0.28375902061401054\n",
      "episode: 61   score: -2 global_step 1268   epsilon: 0.2812153809531867\n",
      "episode: 62   score: 1 global_step 1276   epsilon: 0.2789735162078359\n",
      "episode: 63   score: 1 global_step 1285   epsilon: 0.2764727742098891\n",
      "episode: 64   score: 0 global_step 1299   epsilon: 0.2726272140335106\n",
      "episode: 65   score: 0 global_step 1307   epsilon: 0.27045381463518003\n",
      "episode: 66   score: -1 global_step 1315   epsilon: 0.2682977416984114\n",
      "episode: 67   score: 0 global_step 1328   epsilon: 0.26483072173851846\n",
      "episode: 68   score: 0 global_step 1341   epsilon: 0.2614085035996406\n",
      "episode: 69   score: 1 global_step 1354   epsilon: 0.2580305083398651\n",
      "episode: 70   score: 1 global_step 1366   epsilon: 0.25495111561414624\n",
      "episode: 71   score: 1 global_step 1382   epsilon: 0.2509023495884683\n",
      "episode: 72   score: 0 global_step 1398   epsilon: 0.24691788022723601\n",
      "episode: 73   score: 1 global_step 1411   epsilon: 0.24372713693665488\n",
      "episode: 74   score: 0 global_step 1425   epsilon: 0.24033704771580874\n",
      "episode: 75   score: 0 global_step 1439   epsilon: 0.23699411247654112\n",
      "episode: 76   score: -2 global_step 1456   epsilon: 0.23299728317032256\n",
      "episode: 77   score: 1 global_step 1465   epsilon: 0.2309086759815403\n",
      "episode: 78   score: 0 global_step 1478   epsilon: 0.22792480819542846\n",
      "episode: 79   score: 0 global_step 1495   epsilon: 0.22408092978220462\n",
      "episode: 80   score: -1 global_step 1511   epsilon: 0.22052239953879277\n",
      "episode: 81   score: 0 global_step 1523   epsilon: 0.217890636816753\n",
      "episode: 82   score: 0 global_step 1531   epsilon: 0.21615360047341434\n",
      "episode: 83   score: 0 global_step 1540   epsilon: 0.21421598146907636\n",
      "episode: 84   score: 0 global_step 1554   epsilon: 0.21123637362220768\n",
      "episode: 85   score: 1 global_step 1565   epsilon: 0.2089243567285215\n",
      "episode: 86   score: 1 global_step 1577   epsilon: 0.20643100759521713\n",
      "episode: 87   score: 1 global_step 1589   epsilon: 0.2039674146377742\n",
      "episode: 88   score: 1 global_step 1603   epsilon: 0.20113035782720212\n",
      "episode: 89   score: -3 global_step 1637   epsilon: 0.19440356549968224\n",
      "episode: 90   score: 0 global_step 1651   epsilon: 0.1916995357384587\n",
      "episode: 91   score: 0 global_step 1671   epsilon: 0.18790175032382853\n",
      "episode: 92   score: 0 global_step 1688   epsilon: 0.18473284787922306\n",
      "episode: 93   score: 0 global_step 1699   epsilon: 0.1827109164391416\n",
      "episode: 94   score: 1 global_step 1711   epsilon: 0.1805304042562526\n",
      "episode: 95   score: 0 global_step 1719   epsilon: 0.17909120577644616\n",
      "episode: 96   score: 0 global_step 1730   epsilon: 0.17713102303819148\n",
      "episode: 97   score: 1 global_step 1751   epsilon: 0.17344823454150116\n",
      "episode: 98   score: 0 global_step 1760   epsilon: 0.1718934300192521\n",
      "episode: 99   score: 1 global_step 1769   epsilon: 0.17035256289514833\n",
      "episode: 100   score: 1 global_step 1778   epsilon: 0.16882550823318393\n",
      "episode: 101   score: 1 global_step 1796   epsilon: 0.16581234214129428\n",
      "episode: 102   score: 0 global_step 1805   epsilon: 0.16432598639897444\n",
      "episode: 103   score: -1 global_step 1815   epsilon: 0.16269010151972138\n",
      "episode: 104   score: 0 global_step 1833   epsilon: 0.15978643901921685\n",
      "episode: 105   score: 1 global_step 1845   epsilon: 0.15787951258191282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 106   score: 1 global_step 1859   epsilon: 0.15568350913099022\n",
      "episode: 107   score: 1 global_step 1873   epsilon: 0.15351805068921792\n",
      "episode: 108   score: 0 global_step 1885   epsilon: 0.1516859325741916\n",
      "episode: 109   score: -1 global_step 1904   epsilon: 0.14882969175225835\n",
      "episode: 110   score: 1 global_step 1916   epsilon: 0.1470535255419077\n",
      "episode: 111   score: 1 global_step 1927   epsilon: 0.1454440004894796\n",
      "episode: 112   score: 1 global_step 1940   epsilon: 0.1435645316219759\n",
      "episode: 113   score: 1 global_step 1958   epsilon: 0.14100221871554078\n",
      "episode: 114   score: 1 global_step 1971   epsilon: 0.13918014781929933\n",
      "episode: 115   score: 1 global_step 1983   epsilon: 0.13751914138437535\n",
      "episode: 116   score: 1 global_step 1995   epsilon: 0.1358779577648463\n",
      "episode: 117   score: 1 global_step 2007   epsilon: 0.134256360390882\n",
      "episode: 118   score: 1 global_step 2019   epsilon: 0.13265411551592862\n",
      "episode: 119   score: 1 global_step 2036   epsilon: 0.13041694662196698\n",
      "episode: 120   score: 1 global_step 2055   epsilon: 0.12796120006398387\n",
      "episode: 121   score: 1 global_step 2075   epsilon: 0.12542614343294137\n",
      "episode: 122   score: 1 global_step 2094   epsilon: 0.12306437352500618\n",
      "episode: 123   score: 1 global_step 2103   epsilon: 0.12196121415881125\n",
      "episode: 124   score: 1 global_step 2122   epsilon: 0.11966468874830531\n",
      "episode: 125   score: 1 global_step 2131   epsilon: 0.11859200444159435\n",
      "episode: 126   score: 1 global_step 2146   epsilon: 0.1168255227375973\n",
      "episode: 127   score: -2 global_step 2180   epsilon: 0.11291830038439628\n",
      "episode: 128   score: 1 global_step 2231   epsilon: 0.10730111432922863\n",
      "episode: 129   score: 1 global_step 2247   epsilon: 0.10559711273987664\n",
      "episode: 130   score: 1 global_step 2262   epsilon: 0.10402419584275335\n",
      "episode: 131   score: 0 global_step 2276   epsilon: 0.10257728554188948\n",
      "episode: 132   score: 0 global_step 2294   epsilon: 0.10074650533676789\n",
      "episode: 133   score: 1 global_step 2312   epsilon: 0.09894840055429721\n",
      "episode: 134   score: 1 global_step 2333   epsilon: 0.09689113229559868\n",
      "episode: 135   score: 1 global_step 2373   epsilon: 0.09309011359407375\n",
      "episode: 136   score: 1 global_step 2392   epsilon: 0.09133723000062824\n",
      "episode: 137   score: 1 global_step 2410   epsilon: 0.08970706020433838\n",
      "episode: 138   score: 1 global_step 2425   epsilon: 0.08837083284806357\n",
      "episode: 139   score: 1 global_step 2435   epsilon: 0.08749109062109678\n",
      "episode: 140   score: 1 global_step 2446   epsilon: 0.0865334862270506\n",
      "episode: 141   score: 1 global_step 2456   epsilon: 0.0856720350057922\n",
      "episode: 142   score: 1 global_step 2465   epsilon: 0.08490406369833321\n",
      "episode: 143   score: 0 global_step 2484   epsilon: 0.08330532313902275\n",
      "episode: 144   score: 1 global_step 2498   epsilon: 0.08214659915956658\n",
      "episode: 145   score: 1 global_step 2509   epsilon: 0.0812474911046467\n",
      "episode: 146   score: 1 global_step 2519   epsilon: 0.08043866259804251\n",
      "episode: 147   score: 0 global_step 2529   epsilon: 0.07963788607611134\n",
      "episode: 148   score: 0 global_step 2573   epsilon: 0.07620811252982171\n",
      "episode: 149   score: 1 global_step 2587   epsilon: 0.0751481062290234\n",
      "episode: 150   score: 1 global_step 2609   epsilon: 0.07351209192417524\n",
      "episode: 151   score: 1 global_step 2619   epsilon: 0.07278027024303808\n",
      "episode: 152   score: 1 global_step 2629   epsilon: 0.07205573393440176\n",
      "episode: 153   score: 1 global_step 2639   epsilon: 0.07133841047151027\n",
      "episode: 154   score: 1 global_step 2650   epsilon: 0.0705575998215706\n",
      "episode: 155   score: 1 global_step 2660   epsilon: 0.06985519046323423\n",
      "episode: 156   score: 1 global_step 2677   epsilon: 0.06867710519555668\n",
      "episode: 157   score: 1 global_step 2690   epsilon: 0.06778964004958347\n",
      "episode: 158   score: 1 global_step 2705   epsilon: 0.06677988260908838\n",
      "episode: 159   score: 1 global_step 2719   epsilon: 0.06585101698071448\n",
      "episode: 160   score: 1 global_step 2732   epsilon: 0.06500007135289768\n",
      "episode: 161   score: 1 global_step 2745   epsilon: 0.06416012188724667\n",
      "episode: 162   score: 1 global_step 2762   epsilon: 0.06307808211516211\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "invalid command name \".!canvas\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-68e9a6d63150>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mglobal_step\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mnext_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - 고려대학교\\삽질\\RL_practice\\6-deep-sarsa\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_rewards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mnext_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - 고려대학교\\삽질\\RL_practice\\6-deep-sarsa\\environment.py\u001b[0m in \u001b[0;36mmove_rewards\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mnew_rewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coords'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoords_to_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mnew_rewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - 고려대학교\\삽질\\RL_practice\\6-deep-sarsa\\environment.py\u001b[0m in \u001b[0;36mmove_const\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmove_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mbase_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mcoords\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2467\u001b[0m         return [self.tk.getdouble(x) for x in\n\u001b[0;32m   2468\u001b[0m                            self.tk.splitlist(\n\u001b[1;32m-> 2469\u001b[1;33m                    self.tk.call((self._w, 'coords') + args))]\n\u001b[0m\u001b[0;32m   2470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Args: (val, val, ..., cnf={})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m         \u001b[1;34m\"\"\"Internal function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: invalid command name \".!canvas\""
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWUElEQVR4nO3de7CcdX3H8c+HhISb3BosgYAJl5QBh4I5IqgwKrEgkwHBOqYygEO5Kk4vUwsxI1PaiYPQaZ0qFaK1Ay1CKeEmlHJRBp1hApxwMxEDQS4JYD3oCFogmuTbP/bZns05z16fffbZ/M77NbNzdp/b77u/ffZznn32t7uOCAEA0rRd1QUAAMpDyANAwgh5AEgYIQ8ACSPkASBh06suoNGsWbNi7ty5VZcBANuUVatWvRYRe+XNG6qQnzt3rkZHR6suAwC2KbZfbDaP0zUAkDBCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkC/g/PMlu3aRxq+ffvrWt9tdGtWn/frX+dPz1mmnk3Xqy1x8cev2Wt2H+vU332xde97llFOK399WtUW03lZ9Xi/fvN3N49tuG1u25E+XpAUL8re/cWN3dXVTe9mXzZs7r/XAA/vX7osv1ra53XaT5+2449btXnll7+1Mm1a7zJghzZwp7bqrtNtu0v77S/PmSccdJy1aJF16qXTTTZ3tK93yMH2f/MjISGxLH4Zq3AnrIdLsdiuND8HEbUjSBz4gPfRQ83U6rbPVOu1qb3d/8u5/3rZbabVOJ/e3WTutastbt9unRLv7103ts2dLr7ySX1O7/m+0ww7Nw7+Xx6YsBx0kPfts68eurp+1Tpsmbdo0+HabsaVPfUq64YZe1/eqiBjJm8eR/ABETL584Qudrz8x4Ltx/PHj17s5qmw3rdMgnBhUEy+dalf7dddNbqfTdful1/u2dOn49Vdfbb/8bru1335jwEdIK1e2Xj7vsSnzUrduXX4drbz4Yu/t7rRTbRubN0tf/nLzdl94YXK7a9aU1x9btvQe8O1wJF9Ap0e2zbp44vxmQdrJ0UanNbY7iu3EokXSd7/bWW2dHCHn9VPedrt5JdKqtrxt9Xok32q9Tl5BTdxG4/Lt+vaHP6y93G/V9owZ44Ffn7ZypfS+93VXY781e5XSbL956SXpXe/aeplevPaatFfON7xMbHfHHcdPO1bVR93gSL4E7YKxjKPHYdnJ6gHfb7vuWvtbf08DrR17bPtl8k7ZHH107e+jj/a3nl7de2/7ZeoBX9SsWZOnffSj49f32af29623an+POqo/7VaJkB9i9tYv5SXpgx8cXPvdnnZo1Ms/ufqbzd/5ztY1dOPaa3tft66X2vsZBkce2X0Njcvvvntn6wxLgH3845OnPfDA4Npv/Cfz8stbz6v/I9xhh8HV02+lh7ztE22vtb3O9iVlt7ctavWEbjxvKNVeopfVVpk+8Yni29hzz/zpjefjzzyz++32Y1TDww/3tt7Ef+KS9MQTzZefOPIjz+uv509vd15+kOpHzNL4UXOjD30of736qJgiZs7sbLlf/Wr8+iD/6fRdRJR2kTRN0nOSDpA0Q9KTkg5ttvyCBQtikDZt6n3d+nFu4/Vml3bb6PSSt16ndTZbp3H65Ze3b++QQzq/HxP7qZM68+5fs9o3b47YsqV1fzTOu/769vev2Xby9pV2j0N93vvf3/5+N7vMnNm6nWXLuts/6tNXruxuP+q3Z5/tfN+cNq2/dY6NddZHu+xSXf90S9JoNMnVso/kj5K0LiJ+GhG/lXSjpFParNM3rcbc2tL06d2NOKkv281LtyOO6HzZusg5zfDFL7Zfr9X9bbZco/oY+Vaefrr1/Lzau/He97ae31j3tGm1cc6d+vSnm2+rVTsLFozvK53070QPPdR8HHWjvL57++3W2261X7R6LOrn5aty0EGdL1sfS98vjefl8/a3+huzv/lNf9utStkhv6+k9Q23N2TT/p/t82yP2h4dGxsruZz+aDb+OM/jj/enzWXLxq/vvXdn6xQZ+934ErrTdRuHa05sv1N5g6s6bf+aa9qv+453dFfPihXSY4+1XuaEE7rbZp67724+70tf6mwbtrTvvu2Xm+iRR7pfpwwT95fvf3/r23mjYnpVPzj4wQ8mz3vmma1vH354/9qtQqlDKG1/UtIJEXFOdvsMSUdFxOfzlu/3EMpWw/C6DcDGYVSdDJvrZNtHHTV5hEOnD0enww673W4/dDv8sdk62203+Sgu73Ho5b51M/Qzb34/2uiXbtp55JHx4ZNl1dOpiXWfc470zW9WU8u2rsohlBsk7ddwe46kV0pus+/KerOyH0dQebV9+MPFtzsMWr1ML/qYXHBB9+tUFYbtdHKarW5YRtTkIeDLUXbIPyrpYNvzbM+QtFjSHSW32VaRgKj6Y+CdmPgyd9CGNQwbfeMbrefffPNg6uiHyy+fPG1beAwwGKWGfERsknSRpHskPS3ppohYU2abVRvUk6ubNxy3BZ3224EHDqaGfgz5zHPaaeVsF2im9KiIiP+KiPkRcWBELGu/xtTVzT+Ifo84KFOnbxR3Iu+7TrYlK1ZUXYH0ta9VXQEGKbHjwXxlBcGwBIwtzZmz9bT9Gt4JqbrOTr50a9j10ofdfAldUZ/9bOfLXnRReXVg+EyJkG80yHPqO+88uLYmfhz7pZcG13aeqv+x9EPR8/JXXNGfOjpx1VXj11Poe/TPlAv5POeeW85233ij/TL172tJ5YMXg/Db39b+dvN5hV7Uz8t38lUCw2DGjM6XvfTS2t9t6bQfekPIS/rWt/q7vfqHoTt5c3SXXWrL9nLUX3+itqujKmW1v/32te12E2q9ipj8S1fDauPGzvv7sss630fLssce1bU9lUzZkE/hJe1ll1VdwbZt4cKqK5jahuWTtqmbsiEP3Hdf1RVMbd18fw16R8hjaKTw6goYNoR8YghKbItOOqnqCtI1ZUK+Mfy6CcJDD+1/LWiPf1ZTy113VV1BuqZMyPeq3fenIw2HHFJ1BUA5plddwCBxdDj8Bv0YDbK9ww4bXFvbCp6T5ZvSR/Ip7GDHHVd1BejU6tVVV4CpaEqHfBHD8g/iwQerrgDAMCPkASBhhDwAJIyQz7z11vD8RioA9EuyIf+Zz3S3/E471f4S9OinU0+tugJMdcmG/LXXVl3B4I2NVV0BJrrllqorwFQ3pcbJ98MwHs0PY00Yx+ODKiV7JA8AIOQBIGmEPAAkjJAHgIQR8gCQMEIeABI25UN+82bpd7+rugoAKMeUHye/3Xa1CwCkiHjLzJ8/edqFFw6+DgDoJ0I+s3bt5GlXXz34OgCgn0oLedt/Y/tl209kF36PHQAGrOxz8v8YEX9fchsAgCaSeuO11dcEA8BUVPY5+YtsP2X727b3yFvA9nm2R22PjvFduQDQV44C34Nq+35Je+fMWipppaTXJIWkv5M0OyLObrW9kZGRGB0dLVBP/vRO72J9/fryjdvj62IBDCvbqyJiJG9eodM1EbGwwwK+KenOIm0BALpX5uia2Q03T5W0uqy2AAD5ynzj9QrbR6h2uuYFSeeX2BYAIEdpIR8RZ5S1bQBAZ/jEKwAkjJAHgIQR8gCQMEIeABKWfMifeWbVFQBAdZIP+WuvLb6N6Ul9ww+AqST5kO8Hfh4QwLaKkM9xPh/bApAIQj7H8uVVVwAA/UHIA0DCCHkASBghDwAJI+QBIGGEPAAkjJAHgIQR8gCQMEIeABJGyANAwgh5AEgYIQ8ACSPkASBhhHwTF15YdQUAUBwh38TVV1ddAQAUR8gDQMIIeQBIGCEPAAkj5BtEVF0BAPQXIQ8ACSPkASBhhULe9idtr7G9xfbIhHlLbK+zvdb2CcXKBAD0YnrB9VdLOk3SNY0TbR8qabGkwyTtI+l+2/MjYnPB9gAAXSh0JB8RT0fE2pxZp0i6MSI2RsTzktZJOqpIWwCA7pV1Tn5fSesbbm/Ipk1i+zzbo7ZHx8bGSioHAKamtqdrbN8vae+cWUsj4vZmq+VMyx2gGBHLJS2XpJGREQYxAkAftQ35iFjYw3Y3SNqv4fYcSa/0sB0AQAFlna65Q9Ji2zNtz5N0sKRHSmoLANBE0SGUp9reIOkYSXfZvkeSImKNpJsk/VjSf0v6HCNrAGDwCg2hjIhbJd3aZN4yScuKbB8AUAyfeG3j3HOrrgAAekfIt3HVVVVXAAC9I+Tb2H77qisAgN4R8gCQMEIeABJGyANAwgj5FvilKADbOkIeABJGyANAwgh5AEhY0V+GGhr779+f7XAeHkBKkjmSX7++/TIAMNUkE/IAgMkIeQBIGCEPAAkj5AEgYYQ8ACQs6ZB/++2qKwCAaiUzTr4RY90BoCbpI3kAmOoIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCHkASFihkLf9SdtrbG+xPdIwfa7tt2w/kV2uLl4qAKBbRb+7ZrWk0yRdkzPvuYg4ouD2AQAFFAr5iHhakmz3pxoAQF+VeU5+nu3HbT9o+9hmC9k+z/ao7dGxsbESywGAqaftkbzt+yXtnTNraUTc3mS1VyXtHxG/sL1A0m22D4uINyYuGBHLJS2XpJGREb4kGAD6qG3IR8TCbjcaERslbcyur7L9nKT5kka7rhAA0LNSTtfY3sv2tOz6AZIOlvTTMtoCADRXdAjlqbY3SDpG0l2278lmHSfpKdtPSrpZ0gUR8ctipQIAulV0dM2tkm7Nmb5C0ooi2wYAFMcnXgEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCHkASBghDwAJI+QBIGGEPAAkjJAHgIQR8gCQsORC/owzqq4AAIZHciF/3XVVVwAAwyO5kAcAjCPkASBhhDwAJIyQB4CEEfIAkDBCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCoW87Stt/8T2U7Zvtb17w7wlttfZXmv7hOKlAgC6VfRI/j5J746IwyU9I2mJJNk+VNJiSYdJOlHSP9ueVrAtAECXCoV8RNwbEZuymyslzcmunyLpxojYGBHPS1on6agibQEAutfPc/JnS7o7u76vpPUN8zZk0yaxfZ7tUdujY2NjfSwHADC93QK275e0d86spRFxe7bMUkmbJF1fXy1n+cjbfkQsl7RckkZGRnKXAQD0pm3IR8TCVvNtnyVpkaTjI6Ie0hsk7dew2BxJr/RaJACgN0VH15wo6WJJJ0fEmw2z7pC02PZM2/MkHSzpkSJtAQC61/ZIvo2vS5op6T7bkrQyIi6IiDW2b5L0Y9VO43wuIjYXbAsA0KVCIR8RB7WYt0zSsiLbBwAUwydeASBhhDwAJIyQB4CEEfIAkDBCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCHkASFgSIb///lVXAADDKYmQX7++6goAYDglEfIAgHyEPAAkjJAHgIQR8gCQMEIeABJGyANAwgh5AEgYIQ8ACSPkASBhhDwAJIyQB4CEEfIAkLBCIW/7Sts/sf2U7Vtt755Nn2v7LdtPZJer+1MuAKAbRY/k75P07og4XNIzkpY0zHsuIo7ILhcUbAcA0INCIR8R90bEpuzmSklzipcEAOiXfp6TP1vS3Q2359l+3PaDto9ttpLt82yP2h4dGxvrYzkAgOntFrB9v6S9c2YtjYjbs2WWStok6fps3quS9o+IX9heIOk224dFxBsTNxIRyyUtl6SRkZHo5U5ET2sBQPrahnxELGw13/ZZkhZJOj6iFrcRsVHSxuz6KtvPSZovabRwxQCAjhUdXXOipIslnRwRbzZM38v2tOz6AZIOlvTTIm0BALrX9ki+ja9LminpPtuStDIbSXOcpL+1vUnSZkkXRMQvC7YFAOhSoZCPiIOaTF8haUWRbQMAiuMTrwCQMEIeABJGyANAwgh5AEiYY4g+SWR7TNKLBTYxS9JrfSqnX4axJmk46xrGmqThrGsYa5Koqxv9rOldEbFX3oyhCvmibI9GxEjVdTQaxpqk4axrGGuShrOuYaxJoq5uDKomTtcAQMIIeQBIWGohv7zqAnIMY03ScNY1jDVJw1nXMNYkUVc3BlJTUufkAQBbS+1IHgDQgJAHgIQlEfK2T7S91vY625dUWMd+th+w/bTtNbb/LJu+p+37bD+b/d2jgtqmZb/UdWd2e57th7Oa/sP2jApq2t32zdmPwT9t+5iq+8r2X2SP3WrbN9jeoYq+sv1t2z+3vbphWm7fuOafsv3/KdvvGXBdV2aP4VO2b7W9e8O8JVlda22fMKiaGub9le2wPSu7XWlfZdM/n/XHGttXNEwvp68iYpu+SJom6TlJB0iaIelJSYdWVMtsSe/Jrr9DtR83P1TSFZIuyaZfIukrFdT2l5K+I+nO7PZNkhZn16+WdGEFNV0r6Zzs+gxJu1fZV5L2lfS8pB0b+ugzVfSVal/X/R5Jqxum5faNpJNU++lNSzpa0sMDruuPJE3Prn+loa5Ds+fjTEnzsufptEHUlE3fT9I9qn3ActaQ9NWHJd0vaWZ2+51l91WpO+ogLpKOkXRPw+0lkpZUXVdWy+2SPippraTZ2bTZktYOuI45kr4n6SOS7sx28Ncanphb9eGAato1C1RPmF5ZX2Uhv17Snqp9Dfedkk6oqq8kzZ0QELl9I+kaSX+St9wg6pow71RJ12fXt3ouZoF7zKBqknSzpD+U9EJDyFfaV6odMCzMWa60vkrhdE39iVm3IZtWKdtzJR0p6WFJvx8Rr0pS9vedAy7nq5L+WtKW7PbvSfpVRGzKblfRZwdIGpP0r9lppG/Z3lkV9lVEvCzp7yW9pNrvFL8uaZWq76u6Zn0zTM+Bs1U7UpYqrMv2yZJejognJ8yquq/mSzo2O/33oO33ll1XCiHvnGmVjgu1vYtqP5ry55Hz4+UDrmWRpJ9HxKrGyTmLDrrPpqv2UvYbEXGkpP9V7RREZbJz3Keo9nJ5H0k7S/pYzqLDNu54GB5P2V4qaZOk6+uTchYrvS7bO0laKunSvNk50wbZV9Ml7aHaqaIvSLrJtZ/VK62uFEJ+g2rn3urmSHqlolpke3vVAv76iLglm/w/tmdn82dL+vkAS/qApJNtvyDpRtVO2XxV0u62678MVkWfbZC0ISIezm7frFroV9lXCyU9HxFjEfE7SbdIer+q76u6Zn1T+XPA9lmSFkk6PbLzDRXWdaBq/6ifzPb7OZIes713hTXVbZB0S9Q8otqr61ll1pVCyD8q6eBsBMQMSYsl3VFFIdl/5H+R9HRE/EPDrDsknZVdP0u1c/UDERFLImJORMxVrW++HxGnS3pA0h9XUVNW188krbf9B9mk4yX9WBX2lWqnaY62vVP2WNZrqrSvGjTrmzsknZmNHDla0uv10zqDYPtESRdLOjki3pxQ72LbM23Pk3SwpEfKricifhQR74yIudl+v0G1ARE/U8V9Jek21Q60ZHu+agMOXlOZfVXWGw6DvKj2jvkzqr0jvbTCOj6o2kuspyQ9kV1OUu0c+PckPZv93bOi+j6k8dE1B2Q70TpJ/6ns3f4B13OEpNGsv25T7WVspX0l6TJJP5G0WtK/qTbaYeB9JekG1d4X+J1qIfWnzfpGtZf6V2X7/48kjQy4rnWqnU+u7/NXNyy/NKtrraSPDaqmCfNf0Pgbr1X31QxJ/57tX49J+kjZfcXXGgBAwlI4XQMAaIKQB4CEEfIAkDBCHgASRsgDQMIIeQBIGCEPAAn7P9UXe6MP0EBcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env=Env()\n",
    "agent=DeepSARSAgent()\n",
    "global_step=0\n",
    "scores,episodes=[],[]\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done=False\n",
    "    score=0\n",
    "    state=env.reset()\n",
    "    state=np.reshape(state,[1,15])\n",
    "    while not done:\n",
    "        global_step+=1\n",
    "        action=agent.get_action(state)\n",
    "        next_state,reward,done=env.step(action)\n",
    "        next_state=np.reshape(next_state,[1,15])\n",
    "        next_action=agent.get_action(next_state)\n",
    "        agent.train_model(state,action,reward,next_state,next_action,done)\n",
    "        state=next_state\n",
    "        score+=reward\n",
    "        state-copy.deepcopy(next_state)\n",
    "    if done:\n",
    "        scores.append(score)\n",
    "        episodes.append(e)\n",
    "        pylab.plot(episodes, scores, 'b')\n",
    "        print(\"episode:\", e, \"  score:\", score, \"global_step\",\n",
    "                      global_step, \"  epsilon:\", agent.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
