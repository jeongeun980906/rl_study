{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.render = False\n",
    "        self.load_model = False\n",
    "\n",
    "        # 상태와 행동의 크기 정의\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # DQN 하이퍼파라미터\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "\n",
    "        # 리플레이 메모리, 최대 크기 2000\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # 모델과 타깃 모델 생성\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # 타깃 모델 초기화\n",
    "        self.update_target_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./save_model/cartpole_dqn_trained.h5\")\n",
    "\n",
    "    # 상태가 입력, 큐함수가 출력인 인공신경망 생성\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(24, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # 타깃 모델을 모델의 가중치로 업데이트\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # 입실론 탐욕 정책으로 행동 선택\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        # 메모리에서 배치 크기만큼 무작위로 샘플 추출\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = np.zeros((self.batch_size, self.state_size))\n",
    "        next_states = np.zeros((self.batch_size, self.state_size))\n",
    "        actions, rewards, dones = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            states[i] = mini_batch[i][0]\n",
    "            actions.append(mini_batch[i][1])\n",
    "            rewards.append(mini_batch[i][2])\n",
    "            next_states[i] = mini_batch[i][3]\n",
    "            dones.append(mini_batch[i][4])\n",
    "\n",
    "        # 현재 상태에 대한 모델의 큐함수\n",
    "        # 다음 상태에 대한 타깃 모델의 큐함수\n",
    "        target = self.model.predict(states)\n",
    "        target_val = self.target_model.predict(next_states)\n",
    "\n",
    "        # 벨만 최적 방정식을 이용한 업데이트 타깃\n",
    "        for i in range(self.batch_size):\n",
    "            if dones[i]:\n",
    "                target[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * (\n",
    "                    np.amax(target_val[i]))\n",
    "\n",
    "        self.model.fit(states, target, batch_size=self.batch_size,\n",
    "                       epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\박정은\\gym\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 19.0   memory length: 20   epsilon: 1.0\n",
      "episode: 1   score: 15.0   memory length: 36   epsilon: 1.0\n",
      "episode: 2   score: 13.0   memory length: 50   epsilon: 1.0\n",
      "episode: 3   score: 20.0   memory length: 71   epsilon: 1.0\n",
      "episode: 4   score: 9.0   memory length: 81   epsilon: 1.0\n",
      "episode: 5   score: 14.0   memory length: 96   epsilon: 1.0\n",
      "episode: 6   score: 20.0   memory length: 117   epsilon: 1.0\n",
      "episode: 7   score: 17.0   memory length: 135   epsilon: 1.0\n",
      "episode: 8   score: 14.0   memory length: 150   epsilon: 1.0\n",
      "episode: 9   score: 56.0   memory length: 207   epsilon: 1.0\n",
      "episode: 10   score: 27.0   memory length: 235   epsilon: 1.0\n",
      "episode: 11   score: 20.0   memory length: 256   epsilon: 1.0\n",
      "episode: 12   score: 38.0   memory length: 295   epsilon: 1.0\n",
      "episode: 13   score: 13.0   memory length: 309   epsilon: 1.0\n",
      "episode: 14   score: 44.0   memory length: 354   epsilon: 1.0\n",
      "episode: 15   score: 9.0   memory length: 364   epsilon: 1.0\n",
      "episode: 16   score: 30.0   memory length: 395   epsilon: 1.0\n",
      "episode: 17   score: 25.0   memory length: 421   epsilon: 1.0\n",
      "episode: 18   score: 20.0   memory length: 442   epsilon: 1.0\n",
      "episode: 19   score: 10.0   memory length: 453   epsilon: 1.0\n",
      "episode: 20   score: 9.0   memory length: 463   epsilon: 1.0\n",
      "episode: 21   score: 9.0   memory length: 473   epsilon: 1.0\n",
      "episode: 22   score: 31.0   memory length: 505   epsilon: 1.0\n",
      "episode: 23   score: 23.0   memory length: 529   epsilon: 1.0\n",
      "episode: 24   score: 12.0   memory length: 542   epsilon: 1.0\n",
      "episode: 25   score: 23.0   memory length: 566   epsilon: 1.0\n",
      "episode: 26   score: 20.0   memory length: 587   epsilon: 1.0\n",
      "episode: 27   score: 39.0   memory length: 627   epsilon: 1.0\n",
      "episode: 28   score: 11.0   memory length: 639   epsilon: 1.0\n",
      "episode: 29   score: 12.0   memory length: 652   epsilon: 1.0\n",
      "episode: 30   score: 24.0   memory length: 677   epsilon: 1.0\n",
      "episode: 31   score: 59.0   memory length: 737   epsilon: 1.0\n",
      "episode: 32   score: 8.0   memory length: 746   epsilon: 1.0\n",
      "episode: 33   score: 32.0   memory length: 779   epsilon: 1.0\n",
      "episode: 34   score: 11.0   memory length: 791   epsilon: 1.0\n",
      "episode: 35   score: 16.0   memory length: 808   epsilon: 1.0\n",
      "episode: 36   score: 10.0   memory length: 819   epsilon: 1.0\n",
      "episode: 37   score: 15.0   memory length: 835   epsilon: 1.0\n",
      "episode: 38   score: 15.0   memory length: 851   epsilon: 1.0\n",
      "episode: 39   score: 19.0   memory length: 871   epsilon: 1.0\n",
      "episode: 40   score: 69.0   memory length: 941   epsilon: 1.0\n",
      "episode: 41   score: 26.0   memory length: 968   epsilon: 1.0\n",
      "episode: 42   score: 10.0   memory length: 979   epsilon: 1.0\n",
      "episode: 43   score: 14.0   memory length: 994   epsilon: 1.0\n",
      "episode: 44   score: 11.0   memory length: 1006   epsilon: 0.993020965034979\n",
      "episode: 45   score: 15.0   memory length: 1022   epsilon: 0.9772512378214517\n",
      "episode: 46   score: 39.0   memory length: 1062   epsilon: 0.9389138777035492\n",
      "episode: 47   score: 14.0   memory length: 1077   epsilon: 0.9249283295681431\n",
      "episode: 48   score: 26.0   memory length: 1104   epsilon: 0.9002772252562138\n",
      "episode: 49   score: 10.0   memory length: 1115   epsilon: 0.8904235427767183\n",
      "episode: 50   score: 16.0   memory length: 1132   epsilon: 0.8754068367770318\n",
      "episode: 51   score: 26.0   memory length: 1159   epsilon: 0.8520755747117399\n",
      "episode: 52   score: 40.0   memory length: 1200   epsilon: 0.8178301806491574\n",
      "episode: 53   score: 42.0   memory length: 1243   epsilon: 0.7833919908382508\n",
      "episode: 54   score: 15.0   memory length: 1259   epsilon: 0.7709512887465825\n",
      "episode: 55   score: 10.0   memory length: 1270   epsilon: 0.7625130999383466\n",
      "episode: 56   score: 26.0   memory length: 1297   epsilon: 0.7421906713080445\n",
      "episode: 57   score: 20.0   memory length: 1318   epsilon: 0.7267595445649057\n",
      "episode: 58   score: 13.0   memory length: 1332   epsilon: 0.7166507822451117\n",
      "episode: 59   score: 12.0   memory length: 1345   epsilon: 0.7073900163863007\n",
      "episode: 60   score: 13.0   memory length: 1359   epsilon: 0.6975506718651011\n",
      "episode: 61   score: 14.0   memory length: 1374   epsilon: 0.6871603381721801\n",
      "episode: 62   score: 14.0   memory length: 1389   epsilon: 0.6769247732130653\n",
      "episode: 63   score: 12.0   memory length: 1402   epsilon: 0.6681773581762521\n",
      "episode: 64   score: 20.0   memory length: 1423   epsilon: 0.6542850662093624\n",
      "episode: 65   score: 32.0   memory length: 1456   epsilon: 0.6330355783788719\n",
      "episode: 66   score: 160.0   memory length: 1617   epsilon: 0.5388547601058953\n",
      "episode: 67   score: 63.0   memory length: 1681   epsilon: 0.505432274117712\n",
      "episode: 68   score: 71.0   memory length: 1753   epsilon: 0.4703034042831738\n",
      "episode: 69   score: 64.0   memory length: 1818   epsilon: 0.4406916858010624\n",
      "episode: 70   score: 21.0   memory length: 1840   epsilon: 0.4310975930397502\n",
      "episode: 71   score: 75.0   memory length: 1916   epsilon: 0.3995330431643887\n",
      "episode: 72   score: 131.0   memory length: 2000   epsilon: 0.350104061566005\n",
      "episode: 73   score: 44.0   memory length: 2000   epsilon: 0.33469106557869915\n",
      "episode: 74   score: 77.0   memory length: 2000   epsilon: 0.3095652482070879\n",
      "episode: 75   score: 98.0   memory length: 2000   epsilon: 0.2803725781752547\n",
      "episode: 76   score: 85.0   memory length: 2000   epsilon: 0.25725719064833996\n",
      "episode: 77   score: 216.0   memory length: 2000   epsilon: 0.20705154127145922\n",
      "episode: 78   score: 146.0   memory length: 2000   epsilon: 0.17873320245609906\n",
      "episode: 79   score: 194.0   memory length: 2000   epsilon: 0.1470535255419077\n",
      "episode: 80   score: 362.0   memory length: 2000   epsilon: 0.10226986131454316\n",
      "episode: 81   score: 177.0   memory length: 2000   epsilon: 0.0855863629707864\n",
      "episode: 82   score: 67.0   memory length: 2000   epsilon: 0.07995723559482606\n",
      "episode: 83   score: 73.0   memory length: 2000   epsilon: 0.07425127223384173\n",
      "episode: 84   score: 168.0   memory length: 2000   epsilon: 0.06270055853308702\n",
      "episode: 85   score: 72.0   memory length: 2000   epsilon: 0.058284362418015906\n",
      "episode: 86   score: 181.0   memory length: 2000   epsilon: 0.04858149856964864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-55a9eef9a358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# 매 타임스텝마다 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e13d003dec4c>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         self.model.fit(states, target, batch_size=self.batch_size,\n\u001b[1;32m---> 94\u001b[1;33m                        epochs=1, verbose=0)\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m     95\u001b[0m                                           steps_name='steps_per_epoch')\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_train_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "    # DQN 에이전트 생성\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "scores, episodes = [], []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "        # env 초기화\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    while not done:\n",
    "        #env.render()\n",
    "\n",
    "            # 현재 상태로 행동을 선택\n",
    "        action = agent.get_action(state)\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "            # 에피소드가 중간에 끝나면 -100 보상\n",
    "        reward = reward if not done or score == 499 else -100\n",
    "        #print('reward is ',reward)\n",
    "\n",
    "            # 리플레이 메모리에 샘플 <s, a, r, s'> 저장\n",
    "        agent.append_sample(state, action, reward, next_state, done)\n",
    "            # 매 타임스텝마다 학습\n",
    "        if len(agent.memory) >= agent.train_start:\n",
    "            agent.train_model()\n",
    "\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "                # 각 에피소드마다 타깃 모델을 모델의 가중치로 업데이트\n",
    "            agent.update_target_model()\n",
    "\n",
    "            score = score if score == 500 else score + 100\n",
    "                # 에피소드마다 학습 결과 출력\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, scores, 'b')\n",
    "            pylab.savefig(\"./save_graph/cartpole_dqn.png\")\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "                # 이전 10개 에피소드의 점수 평균이 490보다 크면 학습 중단\n",
    "            if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                #agent.model.save_weights(\"./save_model/cartpole_dqn.h5\")\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
