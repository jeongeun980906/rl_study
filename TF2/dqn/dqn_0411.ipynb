{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self,state_size,action_size):\n",
    "        self.action_size=action_size\n",
    "        self.state_size=state_size\n",
    "        \n",
    "        self.discount_factor=0.99\n",
    "        self.learning_rate=0.001\n",
    "        self.epsilon=1.0\n",
    "        self.epsilon_decay=0.999\n",
    "        self.epsilon_min=0.01\n",
    "        self.batch_size=64\n",
    "        self.train_start=1000\n",
    "        \n",
    "        self.memory=deque(maxlen=2000)\n",
    "        self.model=self.build_model()\n",
    "        self.target_model=self.build_model()\n",
    "        \n",
    "        self.update_target_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        model=Sequential()\n",
    "        model.add(Dense(32,input_dim=self.state_size,activation='relu',\n",
    "                       kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32,activation='relu',\n",
    "                       kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size,activation='linear',\n",
    "                       kernel_initializer='he_uniform'))\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def get_action(self,state):\n",
    "        if np.random.rand()<=self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value=self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "    \n",
    "    def append_sample(self,state,action,reward,next_state,done):\n",
    "        self.memory.append((state,action,reward,next_state,done))\n",
    "        \n",
    "    def train_model(self):\n",
    "        if self.epsilon>self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        mini_batch=random.sample(self.memory,self.batch_size)\n",
    "        states=np.zeros((self.batch_size,self.state_size))\n",
    "        next_states=np.zeros((self.batch_size,self.state_size))\n",
    "        actions,rewards,dones=[],[],[]\n",
    "        for i in range(self.batch_size):\n",
    "            states[i]=mini_batch[i][0]\n",
    "            actions.append(mini_batch[i][1])\n",
    "            rewards.append(mini_batch[i][2])\n",
    "            next_states[i]=mini_batch[i][3]\n",
    "            dones.append(mini_batch[i][4])\n",
    "            \n",
    "        q_value=self.model.predict(states)\n",
    "        next_q_value=self.target_model.predict(next_states)\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            if dones[i]:\n",
    "                q_value[i][actions[i]]=rewards[i]\n",
    "            else:\n",
    "                q_value[i][actions[i]]=rewards[i]+self.discount_factor*(\n",
    "                np.amax(next_q_value[i]))\n",
    "            self.model.fit(states,q_value,batch_size=self.batch_size,\n",
    "                          epochs=1,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\박정은\\gym\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env=gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "scores,episodes=[],[]\n",
    "\n",
    "EPISODES=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 23.0   memory length: 23   epsilon: 1.0\n",
      "episode: 1   score: 25.0   memory length: 48   epsilon: 1.0\n",
      "episode: 2   score: 19.0   memory length: 67   epsilon: 1.0\n",
      "episode: 3   score: 43.0   memory length: 110   epsilon: 1.0\n",
      "episode: 4   score: 22.0   memory length: 132   epsilon: 1.0\n",
      "episode: 5   score: 15.0   memory length: 147   epsilon: 1.0\n",
      "episode: 6   score: 17.0   memory length: 164   epsilon: 1.0\n",
      "episode: 7   score: 23.0   memory length: 187   epsilon: 1.0\n",
      "episode: 8   score: 31.0   memory length: 218   epsilon: 1.0\n",
      "episode: 9   score: 10.0   memory length: 228   epsilon: 1.0\n",
      "episode: 10   score: 14.0   memory length: 242   epsilon: 1.0\n",
      "episode: 11   score: 13.0   memory length: 255   epsilon: 1.0\n",
      "episode: 12   score: 10.0   memory length: 265   epsilon: 1.0\n",
      "episode: 13   score: 13.0   memory length: 278   epsilon: 1.0\n",
      "episode: 14   score: 46.0   memory length: 324   epsilon: 1.0\n",
      "episode: 15   score: 11.0   memory length: 335   epsilon: 1.0\n",
      "episode: 16   score: 14.0   memory length: 349   epsilon: 1.0\n",
      "episode: 17   score: 44.0   memory length: 393   epsilon: 1.0\n",
      "episode: 18   score: 14.0   memory length: 407   epsilon: 1.0\n",
      "episode: 19   score: 11.0   memory length: 418   epsilon: 1.0\n",
      "episode: 20   score: 26.0   memory length: 444   epsilon: 1.0\n",
      "episode: 21   score: 40.0   memory length: 484   epsilon: 1.0\n",
      "episode: 22   score: 18.0   memory length: 502   epsilon: 1.0\n",
      "episode: 23   score: 22.0   memory length: 524   epsilon: 1.0\n",
      "episode: 24   score: 19.0   memory length: 543   epsilon: 1.0\n",
      "episode: 25   score: 32.0   memory length: 575   epsilon: 1.0\n",
      "episode: 26   score: 17.0   memory length: 592   epsilon: 1.0\n",
      "episode: 27   score: 43.0   memory length: 635   epsilon: 1.0\n",
      "episode: 28   score: 18.0   memory length: 653   epsilon: 1.0\n",
      "episode: 29   score: 14.0   memory length: 667   epsilon: 1.0\n",
      "episode: 30   score: 16.0   memory length: 683   epsilon: 1.0\n",
      "episode: 31   score: 13.0   memory length: 696   epsilon: 1.0\n",
      "episode: 32   score: 11.0   memory length: 707   epsilon: 1.0\n",
      "episode: 33   score: 11.0   memory length: 718   epsilon: 1.0\n",
      "episode: 34   score: 20.0   memory length: 738   epsilon: 1.0\n",
      "episode: 35   score: 18.0   memory length: 756   epsilon: 1.0\n",
      "episode: 36   score: 42.0   memory length: 798   epsilon: 1.0\n",
      "episode: 37   score: 12.0   memory length: 810   epsilon: 1.0\n",
      "episode: 38   score: 17.0   memory length: 827   epsilon: 1.0\n",
      "episode: 39   score: 21.0   memory length: 848   epsilon: 1.0\n",
      "episode: 40   score: 28.0   memory length: 876   epsilon: 1.0\n",
      "episode: 41   score: 20.0   memory length: 896   epsilon: 1.0\n",
      "episode: 42   score: 19.0   memory length: 915   epsilon: 1.0\n",
      "episode: 43   score: 20.0   memory length: 935   epsilon: 1.0\n",
      "episode: 44   score: 18.0   memory length: 953   epsilon: 1.0\n",
      "episode: 45   score: 16.0   memory length: 969   epsilon: 1.0\n",
      "episode: 46   score: 31.0   memory length: 1000   epsilon: 0.999\n",
      "episode: 47   score: 18.0   memory length: 1018   epsilon: 0.9811700348643991\n",
      "episode: 48   score: 10.0   memory length: 1028   epsilon: 0.9714023696327185\n",
      "episode: 49   score: 17.0   memory length: 1045   epsilon: 0.9550199818235596\n",
      "episode: 50   score: 9.0   memory length: 1054   epsilon: 0.946459102605027\n",
      "episode: 51   score: 17.0   memory length: 1071   epsilon: 0.9304973749532338\n",
      "episode: 52   score: 13.0   memory length: 1084   epsilon: 0.9184732224159486\n",
      "episode: 53   score: 20.0   memory length: 1104   epsilon: 0.9002772252562138\n",
      "episode: 54   score: 17.0   memory length: 1121   epsilon: 0.88509434007808\n",
      "episode: 55   score: 23.0   memory length: 1144   epsilon: 0.8649595394300645\n",
      "episode: 56   score: 18.0   memory length: 1162   epsilon: 0.8495219033622532\n",
      "episode: 57   score: 10.0   memory length: 1172   epsilon: 0.8410648110498392\n",
      "episode: 58   score: 17.0   memory length: 1189   epsilon: 0.8268805241487632\n",
      "episode: 59   score: 23.0   memory length: 1212   epsilon: 0.8080700157548294\n",
      "episode: 60   score: 11.0   memory length: 1223   epsilon: 0.7992255563671304\n",
      "episode: 61   score: 39.0   memory length: 1262   epsilon: 0.7686407469632577\n",
      "episode: 62   score: 16.0   memory length: 1278   epsilon: 0.7564343028582378\n",
      "episode: 63   score: 15.0   memory length: 1293   epsilon: 0.7451668707698216\n",
      "episode: 64   score: 19.0   memory length: 1312   epsilon: 0.7311354045730207\n",
      "episode: 65   score: 62.0   memory length: 1374   epsilon: 0.6871603381721801\n",
      "episode: 66   score: 27.0   memory length: 1401   epsilon: 0.6688462043806328\n",
      "episode: 67   score: 23.0   memory length: 1424   epsilon: 0.6536307811431531\n",
      "episode: 68   score: 21.0   memory length: 1445   epsilon: 0.6400409317729626\n",
      "episode: 69   score: 14.0   memory length: 1459   epsilon: 0.6311383701174348\n",
      "episode: 70   score: 13.0   memory length: 1472   epsilon: 0.6229826200436561\n",
      "episode: 71   score: 83.0   memory length: 1555   epsilon: 0.573338959119908\n",
      "episode: 72   score: 21.0   memory length: 1576   epsilon: 0.561418483038787\n",
      "episode: 73   score: 17.0   memory length: 1593   epsilon: 0.5519503413089615\n",
      "episode: 74   score: 15.0   memory length: 1608   epsilon: 0.5437287905895168\n",
      "episode: 75   score: 13.0   memory length: 1621   epsilon: 0.5367025720391522\n",
      "episode: 76   score: 27.0   memory length: 1648   epsilon: 0.522398424717818\n",
      "episode: 77   score: 34.0   memory length: 1682   epsilon: 0.5049268418435943\n",
      "episode: 78   score: 19.0   memory length: 1701   epsilon: 0.49541908701565013\n",
      "episode: 79   score: 19.0   memory length: 1720   epsilon: 0.48609036287963414\n",
      "episode: 80   score: 12.0   memory length: 1732   epsilon: 0.48028925378937887\n",
      "episode: 81   score: 11.0   memory length: 1743   epsilon: 0.47503240881720094\n",
      "episode: 82   score: 42.0   memory length: 1785   epsilon: 0.45548464994757865\n",
      "episode: 83   score: 17.0   memory length: 1802   epsilon: 0.4478030481625413\n",
      "episode: 84   score: 20.0   memory length: 1822   epsilon: 0.4389315614456469\n",
      "episode: 85   score: 15.0   memory length: 1837   epsilon: 0.43239347672187917\n",
      "episode: 86   score: 62.0   memory length: 1899   epsilon: 0.4063866225452039\n",
      "episode: 87   score: 20.0   memory length: 1919   epsilon: 0.398335642234492\n",
      "episode: 88   score: 17.0   memory length: 1936   epsilon: 0.39161784004119166\n",
      "episode: 89   score: 87.0   memory length: 2000   epsilon: 0.35897147818971\n",
      "episode: 90   score: 31.0   memory length: 2000   epsilon: 0.3480086817607007\n",
      "episode: 91   score: 34.0   memory length: 2000   epsilon: 0.33636955301023425\n",
      "episode: 92   score: 60.0   memory length: 2000   epsilon: 0.31677140557753575\n",
      "episode: 93   score: 20.0   memory length: 2000   epsilon: 0.3104958044435009\n",
      "episode: 94   score: 95.0   memory length: 2000   epsilon: 0.2823430602649749\n",
      "episode: 95   score: 10.0   memory length: 2000   epsilon: 0.2795323012780908\n",
      "episode: 96   score: 26.0   memory length: 2000   epsilon: 0.27235458681947705\n",
      "episode: 97   score: 48.0   memory length: 2000   epsilon: 0.2595841245128649\n",
      "episode: 98   score: 39.0   memory length: 2000   epsilon: 0.24965034435625258\n",
      "episode: 99   score: 102.0   memory length: 2000   epsilon: 0.22543013363724612\n",
      "episode: 100   score: 87.0   memory length: 2000   epsilon: 0.20663764524045758\n",
      "episode: 101   score: 14.0   memory length: 2000   epsilon: 0.20376344722313644\n",
      "episode: 102   score: 12.0   memory length: 2000   epsilon: 0.20133168951671884\n",
      "episode: 103   score: 34.0   memory length: 2000   epsilon: 0.1945981636633456\n",
      "episode: 104   score: 91.0   memory length: 2000   epsilon: 0.1776634806674152\n",
      "episode: 105   score: 73.0   memory length: 2000   epsilon: 0.1651500869836984\n",
      "episode: 106   score: 18.0   memory length: 2000   epsilon: 0.16220251912277667\n",
      "episode: 107   score: 26.0   memory length: 2000   epsilon: 0.15803755013204487\n",
      "episode: 108   score: 14.0   memory length: 2000   epsilon: 0.15583934847946967\n",
      "episode: 109   score: 20.0   memory length: 2000   epsilon: 0.15275199408186566\n",
      "episode: 110   score: 14.0   memory length: 2000   epsilon: 0.15062731114705447\n",
      "episode: 111   score: 12.0   memory length: 2000   epsilon: 0.14882969175225835\n",
      "episode: 112   score: 93.0   memory length: 2000   epsilon: 0.13560633772727437\n",
      "episode: 113   score: 11.0   memory length: 2000   epsilon: 0.13412210403049113\n",
      "episode: 114   score: 169.0   memory length: 2000   epsilon: 0.11325773392623092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 115   score: 110.0   memory length: 2000   epsilon: 0.10145456026018454\n",
      "episode: 116   score: 17.0   memory length: 2000   epsilon: 0.09974356180769112\n",
      "episode: 117   score: 31.0   memory length: 2000   epsilon: 0.09669744692213977\n",
      "episode: 118   score: 16.0   memory length: 2000   epsilon: 0.09516183749001367\n",
      "episode: 119   score: 93.0   memory length: 2000   epsilon: 0.0867068131465305\n",
      "episode: 120   score: 25.0   memory length: 2000   epsilon: 0.08456495652839072\n",
      "episode: 121   score: 79.0   memory length: 2000   epsilon: 0.07813830745782524\n",
      "episode: 122   score: 30.0   memory length: 2000   epsilon: 0.07582783328659772\n",
      "episode: 123   score: 99.0   memory length: 2000   epsilon: 0.06867710519555668\n",
      "episode: 124   score: 66.0   memory length: 2000   epsilon: 0.06428863486834849\n",
      "episode: 125   score: 104.0   memory length: 2000   epsilon: 0.057935529344130744\n",
      "episode: 126   score: 119.0   memory length: 2000   epsilon: 0.05143255252326238\n",
      "episode: 127   score: 77.0   memory length: 2000   epsilon: 0.047619043934701566\n",
      "episode: 128   score: 10.0   memory length: 2000   epsilon: 0.047144990648034346\n",
      "episode: 129   score: 105.0   memory length: 2000   epsilon: 0.0424435613653425\n",
      "episode: 130   score: 85.0   memory length: 2000   epsilon: 0.03898327457803516\n",
      "episode: 131   score: 114.0   memory length: 2000   epsilon: 0.034781152983625885\n",
      "episode: 132   score: 93.0   memory length: 2000   epsilon: 0.031690885887828896\n",
      "episode: 133   score: 141.0   memory length: 2000   epsilon: 0.027521254060442087\n",
      "episode: 134   score: 100.0   memory length: 2000   epsilon: 0.024901014552609298\n",
      "episode: 135   score: 17.0   memory length: 2000   epsilon: 0.02448106696961483\n",
      "episode: 136   score: 14.0   memory length: 2000   epsilon: 0.024140550922482684\n",
      "episode: 137   score: 104.0   memory length: 2000   epsilon: 0.021754943143792824\n",
      "episode: 138   score: 64.0   memory length: 2000   epsilon: 0.02040559200833238\n",
      "episode: 139   score: 34.0   memory length: 2000   epsilon: 0.01972312825078227\n",
      "episode: 140   score: 13.0   memory length: 2000   epsilon: 0.019468260360787675\n",
      "episode: 141   score: 14.0   memory length: 2000   epsilon: 0.01919746926043152\n",
      "episode: 142   score: 45.0   memory length: 2000   epsilon: 0.018352319063218867\n",
      "episode: 143   score: 18.0   memory length: 2000   epsilon: 0.01802477030540644\n",
      "episode: 144   score: 108.0   memory length: 2000   epsilon: 0.016178656991485886\n",
      "episode: 145   score: 27.0   memory length: 2000   epsilon: 0.01574746492138218\n",
      "episode: 146   score: 97.0   memory length: 2000   epsilon: 0.014291012777400084\n",
      "episode: 147   score: 120.0   memory length: 2000   epsilon: 0.01267423030964932\n",
      "episode: 148   score: 51.0   memory length: 2000   epsilon: 0.012043743404400235\n",
      "episode: 149   score: 42.0   memory length: 2000   epsilon: 0.011548138920186161\n",
      "episode: 150   score: 175.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 151   score: 118.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 152   score: 97.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 153   score: 71.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 154   score: 107.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 155   score: 115.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 156   score: 116.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 157   score: 96.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 158   score: 113.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 159   score: 97.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 160   score: 116.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 161   score: 111.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 162   score: 101.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 163   score: 117.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 164   score: 109.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 165   score: 120.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 166   score: 120.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 167   score: 142.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 168   score: 125.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 169   score: 113.0   memory length: 2000   epsilon: 0.009998671593271896\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPISODES):\n",
    "    done=False\n",
    "    score=0\n",
    "    \n",
    "    state=env.reset()\n",
    "    state=np.reshape(state,[1,state_size])\n",
    "    \n",
    "    while not done:\n",
    "        action=agent.get_action(state)\n",
    "        next_state,reward,done,_=env.step(action)\n",
    "        next_state=np.reshape(next_state,[1,state_size])\n",
    "        \n",
    "        agent.append_sample(state,action,reward,next_state,done)\n",
    "        \n",
    "        if len(agent.memory)>=agent.train_start:\n",
    "            agent.train_model()\n",
    "        score+=reward\n",
    "        state=next_state\n",
    "        \n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            \n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes,scores,'b')\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "            if np.mean(scores[-min(3,len(scores)):])>490:\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
