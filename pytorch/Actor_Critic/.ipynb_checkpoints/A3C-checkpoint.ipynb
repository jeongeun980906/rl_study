{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import torch.multiprocessing as mp\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_train_processes = 3\n",
    "learning_rate = 0.0002\n",
    "update_interval = 5\n",
    "gamma = 0.98\n",
    "max_train_ep = 300\n",
    "max_test_ep = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic,self).__init__()\n",
    "        self.fc1=nn.Linear(4,256)\n",
    "        self.fc_actor=nn.Linear(256,2)\n",
    "        self.fc_critic=nn.Linear(256,1)\n",
    "    def actor(self,x,softmax_dim=0):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc_actor(x)\n",
    "        prob=F.softmax(x,dim=sofmax_dim)\n",
    "        return prob\n",
    "    def critic(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        value=self.fc_critic(x)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(global_model,rank):\n",
    "    load_model=ActorCritic()\n",
    "    local_model.load_state_dict(globak_model.state_dict())\n",
    "    optimizer=optim.Adam(global_model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    env=gym.make('CartPole=v1')\n",
    "    \n",
    "    for n_epi in range(max_train_ep):\n",
    "        done=False\n",
    "        s=env.reset()\n",
    "        while not done:\n",
    "            s_lst,a_lst,r_lst=[],[],[]\n",
    "            for t in range(update_interval):\n",
    "                prob=local_model.actor(torch.from_numpy(s).float())\n",
    "                m=Categorical(prob)\n",
    "                a=m.sample().item()\n",
    "                s_prime,r,done,info=env.step(a)\n",
    "                \n",
    "                s_lst.append(s)\n",
    "                a_lst.append(a)\n",
    "                r_lst=append(r/100.0)\n",
    "                \n",
    "                s=s_prime\n",
    "                if done:\n",
    "                    break\n",
    "            s_final=torch.tensor(s_prime,dtype=torch.float)\n",
    "            R=0.0 if done else local_model.critic(s_final).item()\n",
    "            td_target_lst=[]\n",
    "            for reward in r_lst[::-1]:\n",
    "                R=gamma*R+reward\n",
    "                td_target_lst.append([R])\n",
    "            td_target_lst.reverse()\n",
    "            \n",
    "            s_batch,a_batch,td_target=torch.tensor(s_lst,dtype=torch.float),\n",
    "            torch.tensor(a_lst,dtype=torch.float),torch.tensor(td_target_lst)\n",
    "            advantage=td_target-local_model.critic(s_batch)\n",
    "            \n",
    "            pi=local_model.actor(s_batch,softmax=1)\n",
    "            pi_a=pi.gather(1,a_batch)\n",
    "            loss=-torch.log(pi_a)*advantage.detach()+F.smooth_l1_loss(local_model.critic(s_batch),td_target.detach())\n",
    "            print(pi)\n",
    "            print(pi_a)\n",
    "            print(a_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            for global_param,local_param in zip(global_model.parameters(), local_model.parameters()):\n",
    "                global_param._grad=local_param.grad\n",
    "            optimizer.step()\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training process {} reached maximum episode.\".format(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model):\n",
    "    env = gym.make('CartPole-v1')\n",
    "    score = 0.0\n",
    "    print_interval = 20\n",
    "\n",
    "    for n_epi in range(max_test_ep):\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            prob = global_model.pi(torch.from_numpy(s).float())\n",
    "            a = Categorical(prob).sample().item()\n",
    "            s_prime, r, done, info = env.step(a)\n",
    "            s = s_prime\n",
    "            score += r\n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            print(\"# of episode :{}, avg score : {:.1f}\".format(\n",
    "                n_epi, score/print_interval))\n",
    "            score = 0.0\n",
    "            time.sleep(1)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = ActorCritic()\n",
    "global_model.share_memory()\n",
    "\n",
    "processes = []\n",
    "for rank in range(n_train_processes + 1):  # + 1 for test process\n",
    "    if rank == 0:\n",
    "        p = mp.Process(target=test, args=(global_model,))\n",
    "    else:\n",
    "        p = mp.Process(target=train, args=(global_model, rank,))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
