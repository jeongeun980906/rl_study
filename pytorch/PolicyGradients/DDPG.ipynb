{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "lr_mu        = 0.0005\n",
    "lr_q         = 0.001\n",
    "gamma        = 0.99\n",
    "batch_size   = 32\n",
    "buffer_limit = 50000\n",
    "tau          = 0.005 # for target network soft update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer=collections.deque(maxlen=buffer_limit)\n",
    "    def put(self,transition):\n",
    "        self.buffer.append(transition)\n",
    "    def sample(self,n):\n",
    "        mini_batch=random.sample(self.buffer,n)\n",
    "        s_lst,a_lst,r_lst,s_prime_lst,done_mask_lst=[],[],[],[],[]\n",
    "        for transition in mini_batch:\n",
    "            s,a,r,s_prime,done_mask=transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst),\\\n",
    "                        torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float),\\\n",
    "                        torch.tensor(done_mask_lst)\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Munet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Munet,self).__init__()\n",
    "        self.fc1=nn.Linear(3,128)\n",
    "        self.fc2=nn.Linear(128,64)\n",
    "        self.fc_mu=nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        mu=torch.tanh(self.fc_mu(x))*2\n",
    "        return mu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet,self).__init__()\n",
    "        self.fc_s=nn.Linear(3,64)\n",
    "        self.fc_a=nn.Linear(1,64)\n",
    "        self.fc_1=nn.Linear(128,32)\n",
    "        self.fc_3=nn.Linear(32,1)\n",
    "    def forward(self,x,a):\n",
    "        h1=F.relu(self.fc_s(x))\n",
    "        h2=F.relu(self.fc_a(a))\n",
    "        cat=torch.cat([h1,h2],dim=1)\n",
    "        q=F.relu(self.fc_1(cat))\n",
    "        q=self.fc_3(q)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckNoise:\n",
    "    def __init__(self, mu):\n",
    "        self.theta, self.dt, self.sigma = 0.1, 0.01, 0.1\n",
    "        self.mu = mu\n",
    "        self.x_prev = np.zeros_like(self.mu)\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mu,mu_target,q,q_target,memory,q_optimizer,mu_optimizer):\n",
    "    s,a,r,s_prime,done_mask=memory.sample(batch_size)\n",
    "    target=r+gamma*q_target(s_prime,mu_target(s_prime))\n",
    "    q_loss=F.smooth_l1_loss(q(s,a),target.detach())\n",
    "    q_optimizer.zero_grad()\n",
    "    q_loss.backward()\n",
    "    q_optimizer.step()\n",
    "    \n",
    "    mu_loss=-q(s,mu(s)).mean()\n",
    "    mu_optimizer.zero_grad()\n",
    "    mu_loss.backward()\n",
    "    mu_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update(net,net_target):\n",
    "    for param_target,param in zip(net_target.parameters(),net.parameters()):\n",
    "        param_target.data.copy_(param_target.data*(1.0-tau)+param.data*tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of episode :20, avg score : -1616.7\n",
      "# of episode :40, avg score : -1707.1\n",
      "# of episode :60, avg score : -1690.0\n",
      "# of episode :80, avg score : -1508.9\n",
      "# of episode :100, avg score : -1486.9\n",
      "# of episode :120, avg score : -1466.9\n",
      "# of episode :140, avg score : -1512.7\n",
      "# of episode :160, avg score : -1475.9\n",
      "# of episode :180, avg score : -1448.1\n",
      "# of episode :200, avg score : -1424.1\n",
      "# of episode :220, avg score : -1354.5\n",
      "# of episode :240, avg score : -1394.9\n",
      "# of episode :260, avg score : -1322.1\n",
      "# of episode :280, avg score : -1277.5\n",
      "# of episode :300, avg score : -1255.1\n",
      "# of episode :320, avg score : -1571.4\n",
      "# of episode :340, avg score : -1571.1\n",
      "# of episode :360, avg score : -1580.8\n",
      "# of episode :380, avg score : -1495.7\n",
      "# of episode :400, avg score : -1449.2\n",
      "# of episode :420, avg score : -1472.1\n",
      "# of episode :440, avg score : -1475.0\n",
      "# of episode :460, avg score : -1522.0\n",
      "# of episode :480, avg score : -1405.5\n",
      "# of episode :500, avg score : -1494.0\n",
      "# of episode :520, avg score : -1280.2\n",
      "# of episode :540, avg score : -1204.6\n",
      "# of episode :560, avg score : -1152.9\n",
      "# of episode :580, avg score : -948.5\n",
      "# of episode :600, avg score : -680.9\n",
      "# of episode :620, avg score : -296.0\n",
      "# of episode :640, avg score : -218.0\n",
      "# of episode :660, avg score : -188.6\n",
      "# of episode :680, avg score : -184.7\n",
      "# of episode :700, avg score : -377.9\n",
      "# of episode :720, avg score : -453.1\n",
      "# of episode :740, avg score : -190.1\n",
      "# of episode :760, avg score : -225.1\n",
      "# of episode :780, avg score : -156.0\n",
      "# of episode :800, avg score : -338.7\n",
      "# of episode :820, avg score : -568.6\n",
      "# of episode :840, avg score : -394.2\n",
      "# of episode :860, avg score : -275.2\n",
      "# of episode :880, avg score : -232.8\n",
      "# of episode :900, avg score : -242.0\n",
      "# of episode :920, avg score : -220.0\n",
      "# of episode :940, avg score : -163.1\n",
      "# of episode :960, avg score : -214.7\n",
      "# of episode :980, avg score : -177.7\n",
      "# of episode :1000, avg score : -201.6\n",
      "# of episode :1020, avg score : -166.4\n",
      "# of episode :1040, avg score : -155.5\n",
      "# of episode :1060, avg score : -144.1\n",
      "# of episode :1080, avg score : -134.9\n",
      "# of episode :1100, avg score : -145.7\n",
      "# of episode :1120, avg score : -160.1\n",
      "# of episode :1140, avg score : -151.8\n",
      "# of episode :1160, avg score : -189.6\n",
      "# of episode :1180, avg score : -158.0\n",
      "# of episode :1200, avg score : -185.9\n",
      "# of episode :1220, avg score : -135.8\n",
      "# of episode :1240, avg score : -201.0\n",
      "# of episode :1260, avg score : -130.1\n",
      "# of episode :1280, avg score : -146.5\n",
      "# of episode :1300, avg score : -162.9\n",
      "# of episode :1320, avg score : -134.9\n",
      "# of episode :1340, avg score : -156.3\n",
      "# of episode :1360, avg score : -132.4\n",
      "# of episode :1380, avg score : -149.0\n",
      "# of episode :1400, avg score : -176.8\n",
      "# of episode :1420, avg score : -137.6\n",
      "# of episode :1440, avg score : -151.2\n",
      "# of episode :1460, avg score : -172.5\n",
      "# of episode :1480, avg score : -179.4\n",
      "# of episode :1500, avg score : -236.0\n",
      "# of episode :1520, avg score : -145.5\n",
      "# of episode :1540, avg score : -177.3\n",
      "# of episode :1560, avg score : -148.1\n",
      "# of episode :1580, avg score : -329.7\n",
      "# of episode :1600, avg score : -159.4\n",
      "# of episode :1620, avg score : -147.3\n",
      "# of episode :1640, avg score : -146.6\n",
      "# of episode :1660, avg score : -153.7\n",
      "# of episode :1680, avg score : -128.6\n",
      "# of episode :1700, avg score : -146.5\n",
      "# of episode :1720, avg score : -182.9\n",
      "# of episode :1740, avg score : -162.9\n",
      "# of episode :1760, avg score : -149.0\n",
      "# of episode :1780, avg score : -146.1\n",
      "# of episode :1800, avg score : -193.8\n",
      "# of episode :1820, avg score : -155.6\n",
      "# of episode :1840, avg score : -147.8\n",
      "# of episode :1860, avg score : -124.9\n",
      "# of episode :1880, avg score : -116.4\n",
      "# of episode :1900, avg score : -151.9\n",
      "# of episode :1920, avg score : -156.2\n",
      "# of episode :1940, avg score : -153.0\n",
      "# of episode :1960, avg score : -192.0\n",
      "# of episode :1980, avg score : -129.1\n"
     ]
    }
   ],
   "source": [
    "env=gym.make('Pendulum-v0')\n",
    "memory=ReplayBuffer()\n",
    "\n",
    "q,q_target=Qnet(),Qnet()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "mu, mu_target = Munet(), Munet()\n",
    "mu_target.load_state_dict(mu.state_dict())\n",
    "\n",
    "score=0.0\n",
    "print_interval=20\n",
    "\n",
    "mu_optimizer=optim.Adam(mu.parameters(),lr=lr_mu)\n",
    "q_optimizer=optim.Adam(q.parameters(),lr=lr_q)\n",
    "ou_noise=OrnsteinUhlenbeckNoise(mu=np.zeros(1))\n",
    "\n",
    "for n_epi in range(2000):\n",
    "    s=env.reset()\n",
    "    for t in range(300):\n",
    "        a=mu(torch.from_numpy(s).float())\n",
    "        a=a.item()+ou_noise()[0]\n",
    "        s_prime,r,done,info=env.step([a])\n",
    "        memory.put((s,a,r/100.0,s_prime,done))\n",
    "        score+=r\n",
    "        s=s_prime\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    if memory.size()>2000:\n",
    "        for i in range(10):\n",
    "            train(mu,mu_target,q,q_target,memory,q_optimizer,mu_optimizer)\n",
    "            soft_update(mu,mu_target)\n",
    "            soft_update(q,q_target)\n",
    "    if n_epi%print_interval==0 and n_epi!=0:\n",
    "        print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\n",
    "        score = 0.0\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
